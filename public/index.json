[{"categories":["Linux","操作系统"],"content":"cut cut命令用于从文件中的每一行剪切字节、字符和字段并将这些字节、字符和字段输出。 基本用法 cut [选项参数] filename 说明：默认分割符是制表符 参数说明 选项参数 功能 -f 列号，提取第几列 -d 分隔符，按指定分隔符分割列 实践 文件test_cut.txt ni,hao,ya wo,shi,shei ni,shi,bu,shi,sha ni,gan,ma,ma,wo wo,jiu,ma,ni,zen,mo,l 切割cut第一列 cut -d \",\" -f 1 test_cut.txt ni wo ni ni wo 切割第4、5列 cut -d \",\" -f 4,5 test_cut.txt shi,sha ma,wo ni,zen 注意：前面几个空行是因为前面两行没有第四第五列 在test_cut.txt文件中切割出第一列中的wo cut -d \",\" -f 1 test_cut.txt | grep wo wo wo 在test_cut.txt文件中切割出包含wo所在行的第一列 cat test_cut.txt | grep \"wo\" | cut -d \",\" -f 1 wo ni wo 选取系统变量PATH值，获取第2个:开始后的所有路径 echo $PATH | cut -d \":\" -f 2- /usr/local/bin:/usr/sbin:/usr/bin:/usr/local/go/bin:/root/bin ","date":"2024-06-14","objectID":"/linux%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4/:0:1","tags":["Linux","操作系统"],"title":"Linux常用命令","uri":"/linux%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4/"},{"categories":["Golang","面试"],"content":"如果一个结构体的指针类型实现了某个接口，那么该类型的值类型能够调用接口中的方法嘛？ 答案是可以的，只是可以用调用方法，但不是说值类型实现了接口 当时自己以为如果是指针类型时间的接口，那么该类型的值类型方法集中没有对应的方法，应该不能调用。但是后面查资料后发现是可以调用的，原因是Go语言方法的定义就是实例value或pointer可以调用方法，编译器会自动转换。 但是不能说值类型实现了该接口，只有指针类型实现了该接口。 如果方法的接收器都是值类型，那么值类型和接口类型都实现了该接口。 type Human interface { Sleep() } type Student struct { } func (s *Student) Sleep() { } func main() { s := Student{} s.Sleep() s2 := \u0026Student{} s2.Sleep() var h Human // 编译错误：无法将 s (类型 Student) 用作类型 Human 类型未实现 Human，因为 Sleep 方法有指针接收器 h = s } ","date":"2024-06-14","objectID":"/%E9%9D%A2%E8%AF%95%E6%80%BB%E7%BB%9320240613/:0:1","tags":["面试题","Golang"],"title":"面试总结20240613","uri":"/%E9%9D%A2%E8%AF%95%E6%80%BB%E7%BB%9320240613/"},{"categories":["Golang","面试"],"content":"代码中如何检查一个类型是否实现了某个接口的全部方法 创建一个接口类型变量、创建一个类型变量，然后把这个类型变量赋值给接口类型变量（多态），如果编译通过，说明已经实现了全部方法 自己是了解多态的，但是当时没往这方面想 ","date":"2024-06-14","objectID":"/%E9%9D%A2%E8%AF%95%E6%80%BB%E7%BB%9320240613/:0:2","tags":["面试题","Golang"],"title":"面试总结20240613","uri":"/%E9%9D%A2%E8%AF%95%E6%80%BB%E7%BB%9320240613/"},{"categories":["Golang","面试"],"content":"cap方法 只有slice和channel有cap方法，map没有 当时面试官还问我确不确定，当时脑子一热坚定的说确定，因为想着map底层也有扩容，应该也有cap吧，这下再也不会忘记了 ","date":"2024-06-14","objectID":"/%E9%9D%A2%E8%AF%95%E6%80%BB%E7%BB%9320240613/:0:3","tags":["面试题","Golang"],"title":"面试总结20240613","uri":"/%E9%9D%A2%E8%AF%95%E6%80%BB%E7%BB%9320240613/"},{"categories":["Golang","面试"],"content":"go1.22 for循环 在 1.22 之前的版本中，for 循环的变量只创建一次，在每个迭代中为这个变量赋予对应的值。由于这个特性，使用起来很容易犯错，一不小心就会导致意想不到的行为。 解决方法是使用新变量或给闭包函数传参（当时没想到第二点） package main import ( \"fmt\" \"time\" ) func main() { s := []string{\"a\", \"b\"} for _, v := range s { go func(v string) { fmt.Print(v) }(v) } time.Sleep(time.Second * 1) } go1.22中，for 循环的每次迭代都会创建新变量，这将会避免上面的问题 go1.22还新增了对整数类型表达式的支持 package main import \"fmt\" func main() { for i := range 3 { fmt.Println(i) } } ","date":"2024-06-14","objectID":"/%E9%9D%A2%E8%AF%95%E6%80%BB%E7%BB%9320240613/:0:4","tags":["面试题","Golang"],"title":"面试总结20240613","uri":"/%E9%9D%A2%E8%AF%95%E6%80%BB%E7%BB%9320240613/"},{"categories":["Golang","面试"],"content":"singleflight 介绍 singleflight是golang内置的一个包，这个包提供了对重复函数调用的抑制功能，也就是保证并发请求只会有一个实际请求去访问资源，所有并发请求共享实际响应。 通俗的来说就是 singleflight 将相同的并发请求合并成一个请求，进而减少对下层服务的压力，通常用于解决缓存击穿的问题。（当时没想到是缓存击穿的问题，除了可以用singleflight外还可以使用锁机制） 引入：go get golang.org/x/sync 结构 call type call struct { wg sync.WaitGroup // 这些字段在 WaitGroup 结束前写入一次 // 只有在 WaitGroup 结束后才会被读取。 val interface{} err error // 这些字段在 WaitGroup 结束前使用 singleflight 互斥锁进行读写 // 在 WaitGroup 结束后读取但不写入。 dups int chans []chan\u003c- Result } Group：Group 代表分成多个工作组，形成一个命名空间，在这个命名空间中，各工作单元可以重复执行。 type Group struct { mu sync.Mutex // 互斥锁 m map[string]*call // 懒加载 } Result：Result 保存 Do 方法的结果，以便在通道上传递。做异步处理 type Result struct { Val interface{} Err error Shared bool } 方法 func (g *Group) Do(key string, fn func() (interface{}, error)) (v interface{}, err error, shared bool) key：请求的唯一标识，相同的key会被视为并发请求 fn：实际需要执行的函数 v：fn的返回值 err：fn的执行错误 shared：v是否被共享，若存在并发请求，则为true，不存在则为false 方法作用：对同一个key多次调用时，在第一次调用没有执行完的时候，只会执行一次fn，其他的调用会阻塞等待这次调用返回 func (g *Group) DoChan(key string, fn func() (interface{}, error)) \u003c-chan Result 和Do方法类似，不过返回的是chan，也就是同步异步的区别 func (g *Group) Forget(key string) 用于通知Group删除某个key，这样后面继续这个key的调用时就不会阻塞等待了。 demo func TestSingleFightExample(t *testing.T) { var group singleflight.Group // 模拟一个并发请求 for i := 0; i \u003c 5; i++ { go func(i int) { key := \"example\" tmp := i // 将tmp放进去 val, err, _ := group.Do(key, func() (interface{}, error) { // 模拟一次耗时操作 time.Sleep(time.Second) return fmt.Sprintf(\"result_%d\", tmp), nil }) if err != nil { fmt.Println(\"Error:\", err) } fmt.Println(\"Value:\", val) }(i) } // 等待所有请求完成 time.Sleep(3 * time.Second) } 结果：这是一个很随机的过程，0～4都有可能，主要看哪个协程最先进来。 Value: result_2 Value: result_2 Value: result_2 Value: result_2 Value: result_2 问题 singleflight的本质是对某次函数调用的复用，只执行1次，并将执行期间相同的函数返回相同的结果。由此产生一个问题，如果实际执行的函数出了问题，比如超时，则在此期间的所有调用都会超时，由此需要一些额外的方法来控制。 如果超时可以试用select+doChan+context解决 func TestSingleFightTimeout(t *testing.T) { ctx, cancel := context.WithTimeout(context.Background(), 3*time.Second) go doFly(ctx) time.Sleep(2 * time.Second) cancel() // 2秒后超时 } func doFly(ctx context.Context) { var g singleflight.Group key := \"example\" // 使用 DoChan 结合 select 做超时控制 result := g.DoChan(key, func() (interface{}, error) { time.Sleep(5 * time.Second) // 模拟超时 return \"result\", nil }) select { case r := \u003c-result: fmt.Println(\"r\", r.Val) case \u003c-ctx.Done(): fmt.Println(\"done\") return } } 请求失败 如果第一个请求失败了，那么后续所有等待的请求都会返回同一个 error。但实际上可以根据下游能支撑的 rps 定时 forget 这个 key，让更多的请求能有机会走到后续逻辑。 go func() { time.Sleep(100 * time.Millisecond) g.Forget(key) }() 比如1秒内有100个请求过来，正常是第一个请求能执行queryDB，后续99个都会阻塞。增加这个 Forget 之后，每 100ms 就能有一个请求执行 queryDB，相当于是多了几次尝试的机会，相对的也给DB造成了更大的压力，需要根据具体场景进去取舍。 因为有可能前几次是因为DB的抖动导致的查询失败，重试之后就能实现了 ","date":"2024-06-14","objectID":"/%E9%9D%A2%E8%AF%95%E6%80%BB%E7%BB%9320240613/:0:5","tags":["面试题","Golang"],"title":"面试总结20240613","uri":"/%E9%9D%A2%E8%AF%95%E6%80%BB%E7%BB%9320240613/"},{"categories":["Golang"],"content":"深搜 广搜 栈 队列 树 前缀和 双指针 数学公式 正则 滑动窗口 ","date":"2024-06-06","objectID":"/golang%E5%B9%B6%E5%8F%91%E6%A8%A1%E5%9E%8B/:0:0","tags":["Golang","并发"],"title":"Golang并发模型","uri":"/golang%E5%B9%B6%E5%8F%91%E6%A8%A1%E5%9E%8B/"},{"categories":["数据库"],"content":"什么是事务 事务是数据库管理系统执行过程中的一个逻辑单元，由一个有限的数据库操作序列构成。这些操作要么全部执行，要么全部不执行，是一个不可分割的工作单位。事务由事务开始和事务结束之间的全部数据库操作组成。 ","date":"2024-06-04","objectID":"/mysql%E6%95%B0%E6%8D%AE%E5%BA%93%E4%BA%8B%E5%8A%A1/:0:1","tags":["数据库","MySQL"],"title":"MySQL数据库事务","uri":"/mysql%E6%95%B0%E6%8D%AE%E5%BA%93%E4%BA%8B%E5%8A%A1/"},{"categories":["数据库"],"content":"事务的特性 事务具有四个特性ACID，分别是atomicity原子性、consistency一致性、isolation隔离性、durability一致性 原子性 一个事务必须被事务一个不可分割的最小单元，整个事务的所有操作要么全部成功，要么全部失败。对于一个事务来说不能只执行其中一部分操作。 一致性 一致性是指事务必须使数据库从一种一致状态转换到另一种一致状态。在事务开始之前和事务结束之后，数据库的完整性没有被破坏。 完整性主要包括：实体完整性、域完整性、参照完整性 隔离性 一个事务执行不能被其他事务干扰，即一个事务内部的操作及使用的数据对于其他事务来说是隔离的，并发执行的各个事务之间不能互相干扰。 持久性 一旦事务提交，则其所做的修改就会被永久保存到数据库中，即使系统崩溃，已经提交的数据也不会丢失。 ","date":"2024-06-04","objectID":"/mysql%E6%95%B0%E6%8D%AE%E5%BA%93%E4%BA%8B%E5%8A%A1/:0:2","tags":["数据库","MySQL"],"title":"MySQL数据库事务","uri":"/mysql%E6%95%B0%E6%8D%AE%E5%BA%93%E4%BA%8B%E5%8A%A1/"},{"categories":["数据库"],"content":"并发事务的问题 我们知道MySQL是一个客户端／服务器架构的软件，对于同一个服务器来说，可以有若干个客户端与之连接，每个客户端与服务器连接上之后，就可以称之为一个会话（Session）。每个客户端都可以在自己的会话中向服务器发出请求语句，一个请求语句可能是某个事务的一部分，也就是对于服务器来说可能同时处理多个事务。 在上面我们说过事务有一个称之为隔离性的特性，理论上在某个事务对某个数据进行访问时，其他事务应该进行排队，当该事务提交之后，其他事务才可以继续访问这个数据，这样的话并发事务的执行就变成了串行化执行。 但是对串行化执行性能影响太大，我们既想保持事务的一定的隔离性，又想让服务器在处理访问同一数据的多个事务时性能尽量高些，当我们舍弃隔离性的时候，可能会带来什么样的数据问题呢？ 脏读 当一个事务读取到了另一个事务修改但未提交的数据，被称为脏读。 事务A在执行过程中，对数据资源进行了修改 事务B在A执行修改后读取了数据 由于某些原因A并没有提交事务，而是发生了回滚，则之前的修改应是无效的，但是B已经读取了数据，就是脏数据。 不可重复读 当事务内相同的记录被检索了两次或多次，但是却得到不同的结果时，被称为不可重复读。 在事务B两次读取数据中间，事务A对数据进行了修改操作，导致事务B两次的查询结果不一致。 幻读 在事务执行过程中，如果有两次或多次的范围查询，在这些范围查询之间，另一个事务对这些数据进行添加或删除的操作，导致范围查询的数据条目增加或减少，第一个事务两次或多次范围查询得到的数据条目不一致。 事务B前后两次读取同⼀个范围的数据，在事务B两次读取的过程中事务A新增了数据，导致事务B后⼀次读取到前⼀次查询没有看到的⾏。 注意：幻读和不可重复读有些类似，但是幻读重点强调读取到了之前不存在的数据或之前存在但是后面又没了的数据。 隔离级别 在SQL标准中有四个隔离级别，分别是读未提交（Read Uncommitted）、读已提交（Read Committed）、可重复读（Repeatable Read）、串行化（Serializable） 读未提交 一个事务可以读取另一个事务未提交的数据。这是最低级别的隔离级别，可能会导致脏读、不可重复读和幻读 读已提交 一个事务只能读取另一个已提交事务的数据。可以防止脏读，但会出现不可重复读和幻读。 原理：在读已提交的隔离级别下，事务1先读取数据，但未提交，此事事务2仍然可以继续修改数据。这是因为读已提交的隔离级别关注的是读取的数据是否已经被其他事务提交，而不是本身是否正在读取数据。 可重复读 在一个事务中多次读取同一数据会返回相同结果，即使其他事务已经修改了这些数据并提交。可以防止脏读和不可重复读，但是可能会出现幻读。这一级别是MySQL InnoBD引擎的默认级别。 原理：通过多版本控制并发（MVCC）和行级锁来实现。下面详细介绍什么是MVCC 串行化 最高的隔离级别，要求事务串行执行，即事务之间没有并发。 原理：对于同一行记录，读写分别会加读写锁，出现读写锁冲突时，后访问的事务必须等待前一个事务执行完成才能够继续。 注意：对于四个隔离级别所能避免的事务并发问题，不要死记硬背，很多人都是看一张表格，然后把表格内容背下来，不去理解原理是记不长久的。 ","date":"2024-06-04","objectID":"/mysql%E6%95%B0%E6%8D%AE%E5%BA%93%E4%BA%8B%E5%8A%A1/:0:3","tags":["数据库","MySQL"],"title":"MySQL数据库事务","uri":"/mysql%E6%95%B0%E6%8D%AE%E5%BA%93%E4%BA%8B%E5%8A%A1/"},{"categories":["数据库"],"content":"MVCC MVCC全称Multi Version Concurrency Control，多版本并发控制，主要是为了提升数据库并发性能。在MVCC中有两个非常重要的概念：版本链和ReadView（视图），下面先来介绍这两个概念。 版本链 首先要知道的是，对于使用InnoDB作为存储引擎的表来说，它的聚簇索引记录中都包含两个必要的隐藏列：trx_id和roll_pointer（注意：不是row_id，如果我们创建表的适时候表中有主键，或非NULL的UNIQUE键时都不会包含row_id列）。 trx_id 这个隐藏列用于存储最近一次修改该记录的事务的事务ID。当一个事务对某条聚簇索引记录进行插入或更新时，该事务的ID会被赋值给trx_id。但查询操作本身不会修改记录，因此它不会改变trx_id的值。 roll_pointer 这个隐藏列是一个指向undo日志的指针。当一个事务修改了一条记录时，旧版本的记录会被复制到undo日志中，并且新版本日志中的roll_pointer会指向这个undo日志条目。 注意：为了实现事务的原子性，InnoDB存储引擎在进行实际增删改一条记录时，都需要先把对应的undo日志记下来。一般每对一条记录做一次改动，就对应着一条undo日志，但是一个事务执行过程中，可能新增、删除、修改若干条记录，也就会产生若干条undo日志，这些日志会从0开始编号。 为了理解版本链，我们创建一个演示表teacher CREATE TABLE teacher ( number INT, name VARCHAR(100), domain varchar(100), PRIMARY KEY (number) ) Engine=InnoDB CHARSET=utf8; 然后向表中插入一条数据 INSERT INTO teacher VALUES(1, '李瑾', 'JVM系列'); 假设插入该记录的事务id为60，那么此刻该条记录的示意图如下所示： 假设之后两个事务id分别为80、120的事务对这条记录进行UPDATE操作，操作流程如下： 每次对记录进行改动，都会记录一条undo日志，每条undo日志也都有一个roll_pointer属性（INSERT操作对应的undo日志没有该属性，因为该记录并没有更早的版本），可以将这些undo日志都连起来，串成一个链表，所以现在的情况就像下图一样： 对记录的每次修改都会将旧值放到undo日志当中，就算是该记录的一个旧版本，随着更新次数的增加，所有的版本记录都会被roll_pointer属性连接成一个链表，我们把这个链表称为版本链，版本链的头节点就是这条记录的最新值。另外，每个版本中还包含生成该版本时对应的事务id。于是可以利用这个版本链来控制并发事务访问相同记录的行为，这种机制就叫做MVCC ReadView ReadView是一个事务进行快照读时产生的数据读试图。当事务执行快照读时，会产生一个数据系统当前的快照，这个快照就是ReadView。ReadView提供了选择哪个版本数据的依据，它决定了事务在某一时刻能看到那些版本的数据。 组成部分 m_ids：事务ID集合，表示在生成ReadView时，当前系统中活跃的读写事务的事务id列表 min_trx_id：表示在生成ReadView时，当前系统中活跃的读写事务的id最小值，也就是m_ids中的最小值 max_trx_id：表示在生成ReadView时，当前系统中应该分配的下一个事务的id。并不是m_ids中的最大值。 creator_trx_id：表示生成该ReadView的事务的事务id。 例如，现在有id为1，2，3，4四个事务，其中id为3的事务提交了，其余没有提交，且id为4的事务中进行了快照读操作，那么m_ids=[1，2，3]，min_trx_id=1，creator_id=4，但是max_trx_id=5，因为事务id是自增分配的。 原理 在了解了版本链和ReadView的概念后，我们来看看ReadCommitted是如何解决脏读以及RepeatedRead是如何解决可重复读的问题的。 ReadCommitted ReadCommitted隔离级别中的事务在每次开始执行查询时，都会生成一个独立的ReadView，其中ReadView的creator_trx_id就是当前事务的id。 有了ReadView后，在执行查询时，会先拿自己产生的ReadView的creator_id去和被访问记录的版本的trx_id进行比较。 只能比较不在m_ids列表中的事务id，m_ids列表中的事务处于活跃状态，它的数据对其他事务不可见。（解决脏读问题的关键） 如果creator_trx_id等于trx_id就说明当前事务在访问它自己修改过的记录，所以该版本可以被当前事务访问。 如果被访问版本的trx_id小于creator_trx_id，表明生成该版本的事务是在生成当前ReadView前就以及提交了，所以该版本可以被访问 如果被访问版本的trx_id大于creator_trx_id，就要看trx_id是否小于max_trx_id如果小于，则可见，如果大于则不可见。 下面看个例子： 还是这个图，两个事务，都对同一条记录做修改，但是均未提交，版本链也如之前介绍的一样。若此时执行一条查询语句SELECT * FROM teacher WHERE number = 1;（假设事务id是130） 查询过程： 生成一个ReadView，ReadView的m_ids列表就是[80, 120]（不包含自己的事务id） min_trx_id=80，max_trx_id=131，creator_trx_id=130。 访问版本链的头节点，发现trx_id是120，在活跃事务集合中，不符合要求。继续往下找，直到找到trx_id=60的undo记录，小于当前的creator_trx_id，符合要求。 返回结果：得到的列name的值为’李瑾’的记录。 思考一下：为什么只能解决脏读，无法解决不可重复读问题呢？下面简单文字描述一下 因为ReadCommited隔离级别是每次查询时都会生成一个ReadVew，那么如果在同一个事务（T1）内部的两个查询（S1和S2）之间，有另外一个事务（T2）对记录进行修改并提交。 T2在第一个S1开始前执行，在S2开始前提交 S1开始前产生的ReadView中的m_ids中会包含T2，因为此时T2已经开始执行，处于活跃状态。所以S1看不到T2的结果 S2开始前T2结束，则S2产生的ReadView中不包含T2，且此时的ReadView中的max_trx_id一定大于T2，故S2可以看到T2的结果。 T2在S1结束后，S2开始前执行并提交。这个过程比较简单不做赘述 Repeatable Read 这个的原理和Read Committed基本一致，唯一存在区别的是Repeatable Read并不是在每次查询都会生成一个新的ReadView，而是一个事务中的所有查询都共用一个ReadView，这样自然可以解决可重复读问题。 Repeatable Read幻读现象 除了MVCC以外，还有行级锁和间隙锁，这三者共同帮助Repeatable Read预防大部分的幻读问题 在InnoDB中为了防止幻读，当使用范围条件查询时，除了对查询到的行加行锁（Record Locks）外，还会对查询范围内的间隙（Gap）加间隙锁。间隙锁阻止其他事务在这个间隙内插入新的记录，从而确保了在这个事务的后续查询中，不会出现“幻影”行（即之前不存在的行）。 间隙锁和行锁的结合被称为Next-Key Locks。这种锁类型不仅锁定了记录本身，还锁定了记录之前的间隙，从而防止其他事务在这个范围内插入新的记录。 为什么说预防大部分的幻读问题？下面来看看可能会出现的幻读问题 原始数据 首先在事务T1中执行select * from teacher where number = 30;很明显，这个时候是找不到number = 30的记录的。 在事务T2中，执行insert into teacher values(30,'豹','数据湖');并提交 在事务T1，依次执行 select * from teacher where number = 30; update teacher set domain='RocketMQ' where number=30; select * from teacher where number = 30; 事务1明显出现了幻读的情况，这是为什么？ 在REPEATABLE READ隔离级别下，T1第一次执行普通的SELECT 语句时生成了一个ReadView（但是版本链没有），之后T2向teacher 表中新插入一条记录并提交，然后T1也进行了一个update语句。 ReadView并不能阻止T1执行UPDATE 或者DELETE 语句来改动这个新插入的记录，但是这样一来，这条新记录的trx_id隐藏列的值就变成了T1的事务id。 之后T1再使用普通的SELECT 语句去查询这条记录时就可以看到这条记录了，也就可以把这条记录返回给客户端。因为这个特殊现象的存在，我们也可以认为MVCC 并不能完全禁止幻读（就是第一次读如果是空的情况，且在自己事务中进行了该条数据的修改）。 ","date":"2024-06-04","objectID":"/mysql%E6%95%B0%E6%8D%AE%E5%BA%93%E4%BA%8B%E5%8A%A1/:0:4","tags":["数据库","MySQL"],"title":"MySQL数据库事务","uri":"/mysql%E6%95%B0%E6%8D%AE%E5%BA%93%E4%BA%8B%E5%8A%A1/"},{"categories":["Golang"],"content":"defer实践遇到的坑 defer用来声明一个延迟函数，把这个函数放入到一个栈上，当外部的包含方法return之前，返回参数到调用方法之前调用，也可以说是运行到最外层方法体时调用。我们经常用他来做一些资源的释放，比如关闭io操作。 但是在两个场景下需要特别注意：1. defer涉及参数传递 2. defer涉及对返回值的操作 参数传递 在定义defer时传递的参数是作为值拷贝传递的，也就是说如果原来的值发生变化，不会影响defer中的值。 func main() { a, b, c := 1, 2, 3 defer func(a, b, c int) { fmt.Println(a, b, c) }(a, b, c) a, b, c = 4, 5, 6 defer fmt.Println(a, b, c) fmt.Println(a, b, c) } 输出： 4 5 6 4 5 6 1 2 3 当遇到在一个方法中对原数据进行改动，但是最后又想要使用原数据进行一些操作时，可以用到这个特性。 注意：如果defer传递的是指针，那么，外面的改动还是会影响defer内部的值的，道理很简单，指向同一块空间，自然是同步的。 对返回值操作 在defer中对返回值进行操作，大致根据返回值类型可以分为两大类：返回匿名变量和返回命名变量。 对于返回匿名变量，无论defer中怎么操作，都不会改变最终的返回值。 对于命名变量，只有一种情况不会修改返回值，那就是通过只拷贝将变量传递到defer函数内。 func main() { fmt.Println(deferFun()) fmt.Println(deferFun1()) fmt.Println(deferFun2()) fmt.Println(deferFun3()) fmt.Println(deferFun4()) fmt.Println(deferFun5()) } func deferFun() (a, b, c int) { a, b, c = 1, 2, 3 defer func() { a, b, c = 4, 5, 6 }() return } func deferFun1() (a, b, c int) { a, b, c = 1, 2, 3 defer func(a, b, c int) { a, b, c = 4, 5, 6 }(a, b, c) return } func deferFun2() (a, b, c int) { a, b, c = 1, 2, 3 defer func(a, b, c *int) { *a, *b, *c = 4, 5, 6 }(\u0026a, \u0026b, \u0026c) return } func deferFun3() (int, int, int) { a, b, c := 1, 2, 3 defer func() { a, b, c = 4, 5, 6 }() return a, b, c } func deferFun4() (int, int, int) { a, b, c := 1, 2, 3 defer func(a, b, c int) { a, b, c = 4, 5, 6 }(a, b, c) return a, b, c } func deferFun5() (int, int, int) { a, b, c := 1, 2, 3 defer func(a, b, c *int) { *a, *b, *c = 4, 5, 6 }(\u0026a, \u0026b, \u0026c) return a, b, c } 输出： 4 5 6 1 2 3 4 5 6 1 2 3 1 2 3 1 2 3 原理 对返回值的操作，归根结底是defer和return的顺序问题，实际上defer函数的执行既不是在return之后也不是在return之前，而是return语句包含了对defer函数的调用，即return会被翻译成下面几条伪指令： 保存返回值到栈上，如果是匿名变量，需要在栈上定义变量并赋值（程序员无需理会） 如果有defer函数，则调用defer函数 调整函数栈 返回（如果是匿名变量，直接返回新定义的变量，如果是命名变量，直接返回命名变量） 命名变量返回时，不会创建新的变量，所以defer的修改会返回去。 而匿名变量，会创建新的变量，defer中的修改，还是修改原来的变量，所以修改不能返回去。 ","date":"2024-06-03","objectID":"/golang%E5%AE%9E%E8%B7%B5%E4%B8%AD%E7%9A%84%E6%B3%A8%E6%84%8F%E4%BA%8B%E9%A1%B9%E6%8C%81%E7%BB%AD%E6%9B%B4%E6%96%B0/:0:1","tags":["Golang"],"title":"Golang实践中的注意事项（持续更新）","uri":"/golang%E5%AE%9E%E8%B7%B5%E4%B8%AD%E7%9A%84%E6%B3%A8%E6%84%8F%E4%BA%8B%E9%A1%B9%E6%8C%81%E7%BB%AD%E6%9B%B4%E6%96%B0/"},{"categories":["数据库"],"content":"什么是MySQL调优 MySQL调优是指对MySQL数据库进行性能优化的一系列操作，旨在提高数据库的运行效率、响应速度和稳定性。简单来说MySQL调优就是将原本执行较慢的SQL语句，通过一些列的优化转换成执行相对较快的SQL语句。 在MySQL的各种语句中（SELECT UPDATE INSERT DROP），SELECT语句往往是最需要进行调优的 ","date":"2024-05-31","objectID":"/mysql%E8%B0%83%E4%BC%98/:0:1","tags":["MySQL","数据库"],"title":"MySQL调优","uri":"/mysql%E8%B0%83%E4%BC%98/"},{"categories":["数据库"],"content":"调优金字塔 MySQL调优可以从多个方面进行，包括架构调优、MySQL本身调优、硬件调优 越往上成本、难度越来越高，但是带来的收益却是越来越小，所以在优化时，往往优先考虑下方的优化方式 架构调优 在进行架构设计时，首先要考虑业务的实际情况，是否可以把不适合数据库做的事情放在其他服务中，如数据仓库、搜索引擎、数据缓存等等 考虑数据库的并发量是否较大，是否采用分布式架构 考虑读的压力是否较大，是否需要读写分离 MySQL调优 设计合理的表结构 优化SQL语句 添加索引 硬件调优 这个一般不需要太多的关注，如果是DBA的话，需要自己去学一些操作系统和硬件的知识 ","date":"2024-05-31","objectID":"/mysql%E8%B0%83%E4%BC%98/:0:2","tags":["MySQL","数据库"],"title":"MySQL调优","uri":"/mysql%E8%B0%83%E4%BC%98/"},{"categories":["数据库"],"content":"慢查询 什么是慢查询 慢查询就是一条SELECT语句执行需要花费大量时间，这个时间往往不被系统或用户能接受（比如10s钟） 在MySQL中慢查询就是指执行时间超过MySQL服务器所设定的long_quer_time时间的SELECT语句，所有超过该时间的语句都会被记录在慢查询日志中。 在MySQL中可以通过show VARIABLES like '%slow_query_time%' set global long_query_time=0来查看和设置慢查询的时间阈值。（设置为0，就表示任何查询都是慢查询，都会被记录在慢查询日志中） 在MySQL中可以通过show VARIABLES like 'slow_query_log'和set GLOBAL slow_query_log=1来查询和开启慢查询日志，如果慢查询日志没有开启，则不会被记录。 如果希望将没有使用索引的SELECT语句也记录在慢查询日志中，可以通过set VARIABLES 'log_queries_not_using_indexes'来开启 在MySQL中通过show VARIABLES like '%slow_query_log_file%'来查看慢日志所在的磁盘位置 为何会产生慢查询 其实产生慢查询的最终原因就是因为MySQL服务器要扫描的数据过多，这里可以是因为要扫描的数据行过多，也可能是因为要返回的数据列过多。所以MySQL调优主要是尽可能的让MySQL服务器只扫描自己需要的数据，不去扫描额外的数据，这样就能将MySQL性能发挥到最大。 几个概念 响应时间：响应时间是指语句执行所花费的时间，它由服务时间和排队时间两个部分组成 排队时间是指服务器因为等待某些资源而没有真正执行查询的时间，可能是等待IO操作完成，或等待行锁 服务时间是指这条SELECT语句真正执行的时间 这两个时间可以通过慢查询日志查看 扫描行数：MySQL为了找到目标的数据，在服务器中所扫描的记录数 返回行数：最终需要的记录数 显然对于一条SELECT语句，响应时间越短越好，扫描行数与返回行数的比，越小越好，但是最小是1，即扫描多少条数据，返回多少条数据 如果发现查询需要扫描大量的数据，但是只返回少量的数据，那么可以通过下面几种方法尝试优化： 使用覆盖索引，把所有需要使用的列都放到索引中，减少回表次数 改变库表结构，例如使用汇总表 这个查询频繁使用，访问大量数据并进行复杂计算 对实时性要求不高，可以接受一定程度的延迟更新汇总数据 如果SELECT较为复杂，可以尝试重写优化，让MySQL优化器能够以更优化的方式执行这个查询 注意：在一条SELECT语句中，除非特殊情况，否则一定要避免使用SELECT * FROM table，最好是按需查询。我自己在刚工作时，就遇到过这种情况，在一张有两万多条记录的表中，有四五条记录的一个字段数据非常大（大约几MB），所以我当时使用SELECT *时，一直报慢查询相关错误，恰巧这个字段我并不需要。但是后面还是有大佬通过一些压缩算法把数据压缩了。 ","date":"2024-05-31","objectID":"/mysql%E8%B0%83%E4%BC%98/:0:3","tags":["MySQL","数据库"],"title":"MySQL调优","uri":"/mysql%E8%B0%83%E4%BC%98/"},{"categories":["数据库"],"content":"执行计划 什么是执行计划 前面说了慢查询会被记录在慢查询日志中，那么如何排查这条慢查询是因何而导致呢？是因为没有使用索引？还是因为扫描的记录数较多？这时候就需要用到执行计划去排查究竟是什么原因了。 执行计划就是一条语句在经过MySQL查询优化器的各种基于成本和规则的优化后生成的一个执行计划，该计划展示了接下来具体执行的查询的方式，具体可以看到下面这些信息： 表的读取顺序 数据读取操作的操作类型（下面会有详细介绍） 哪些索引可以使用、哪些索引被实际使用 表之间的引用 每张表有多少行被优化查询 在MySQL中可以通过EXPLAIN关键字查看执行计划，进行分析 概览 通过EXPLAIN SELECT ****语句得到的执行计划一般如下表所示（先有个大致概念，后面会详细介绍） 字段名称 id select_type table partitions type possible_keys key key_len ref rows filtered extra 注释 一般一个SELECT对应一个id（有例外情况） 查询的类型 表名 匹配的分区信息 针对单表的访问方法 可能用到的索引 实际用到的索引 实际使用到的索引长度 当使用索引列等值查询时，与索引列进行等值匹配的对象信息 预估的需要读取的记录条数 某个表经过搜索条件过滤后剩余记录条数的百分比 一些额外信息 id 在MySQL中，一般情况下一个SELECT关键字对应一个id，比如下面这个虽然它查询了两张表，但是只有一个SELECT关键字，所以只有一个id 下面条SQL语句有两个SELECT关键字，故有两个id 特殊情况 上面说一个SELECT关键字对应一个id，但是有一些情况比较特殊，即使有多个SELECT关键字，但是执行计划里只有一个id，下面我们来看看这些情况。 包含子查询 很多时候MySQL的查询优化器会将涉及子查询的查询语句进行重写，转换成连接查询，这时候即使你自己写的查询语句有两个SELECT关键字，但是通过MySQL优化器优化过后只有一个SELECT关键字，所以执行计划中只有一个id。 --优化前 SELECT * FROM user_basic WHERE user_basic.id IN (SELECT contact.id FROM contact WHERE contact.id \u003c 10); --优化后 SELECT user_basic.* FROM user_basic JOIN contact ON user_basic.id = contact.id WHERE contact.id \u003c 10; 为什么要优化？这里只能简述子查询被优化成JOIN的原因，其他查询语句的优化，容我后面专门写一篇文章讲解 临时表的使用：执行子查询时，MySQL需要为内层查询语句（子查询）的查询结果建立一个临时表，然后外层查询语句从这个临时表中查询记录。这个过程会消耗大量的CPU和IO资源，产生大量的慢查询 索引问题：子查询结果集存储的临时表，不论是内存临时表还是磁盘临时表，通常都不会存在索引，这会导致查询性能低下 结果集过大的问题：如果子查询的结果集数量过多，会导致内存不足够建立临时表，从而会在磁盘中建立临时表。且如果涉及写操作，数据集大可能会导致持有锁的时间更长，影响其他并发查询的性能。 包含UNION子句 先观察下面这张图，看看有何不同 EXPLAIN SELECT * FROM user_basic UNION SELECT * FROM user_basic; 虽然有两个SELECT语句，但是在执行计划中却有三个id，这是为什么？UNION子句会对并集的结果进行去重，怎么去重呢？MySQL使用的是内部的临时表，上图中UNION子句为了把id为1和2的结果集并集去重，在内部建立了一个名称为\u003cunion1,2\u003e的临时表。 和UNION比起来，UNION ALL不需要去重，所有只有两个id table 不论查询语句有多复杂，里面包含了多少张表，到最后也是对单表进行访问，MySQL规定EXPLAIN语句输出的每条记录对应着某个单表的访问方法/访问类型，该条记录的table列代表着该表的表名 partitions 和分区有关，一般情况下都是null type 前面说EXPLAIN语句输出的每条记录对应着某个单表的访问方法/访问类型，其中type列就是具体的访问类型/访问方法，是一个非常重要的指标。出现较多的有七个值，结果值从好到坏依次是 system \u003e const \u003e eq_ref \u003e ref \u003e range \u003e index \u003e all 一般来说，要保证查询至少达到range类型，最好能达到ref，下面分别介绍这几个的概念 system 当表中只有一条记录，且该表使用的存储引擎的统计数据是精确的，比如MyISAM、Memory那么对该表的访问类型就是system 解释：什么是存储引擎的统计数据是精确的，存储引擎可以精确的维护表的大小和记录的统计信息，这使得查询优化器能够基于这些准确的数据做出更好的决策。具体原因可能要单独一篇文章解释，不知道我是否有时间能更新，望谅解。 const 当我们根据主键或唯一二级索引列与常数进行等值匹配时，对单表的访问就是const，因为只匹配一行，所以非常快。注意加粗字体！！ EXPLAIN SELECT * FROM user_basic UNION ALL SELECT * FROM user_basic; 如果二级索引列有多列的话，那么每一列都需要与常数进行等值匹配，最后的访问类型type才是const EXPLAIN SELECT phone,email FROM user_basic WHERE phone = '110' AND email = '2923780891@qq.com'; 对于唯一二级索引来说，查询该列为NULL值的情况比较特殊，因为唯一二级索引列并不限制 NULL 值的数量，所以上述语句可能访问到多条记录，也就是说is null不可以使用const访问方法来执行。 EXPLAIN SELECT phone,email FROM user_basic WHERE phone IS NUL eq_ref 在连接查询中，如果被驱动表是通过主键或唯一二级索引列等值匹配的方式进行访问的，则对该驱动表的访问类型是eq_ref。 注意：A表和B表进行连接查询，如果通过A表的结果集作为循环基础数据，然后一条一条的通过结果集中的数据作为过滤条件到B表中查询，然后合并结果，那么A表就是驱动表，B表就是被驱动表 EXPLAIN SELECT * FROM user_basic u1 LEFT JOIN user_basic u2 ON u1.id = u2.id 从执行结果中看，被驱动表是u2，驱动表是u1，u2的访问方式是eq_ref，表明在访问u2表时可以通过主键进行等值匹配来访问。 ref 当通过普通二级索引列与等值进行匹配时，那么对该表的访问方法可能是ref。本质上也是一种索引访问，但是不是唯一索引，索引可能会有多条匹配的结果。 EXPLAIN SELECT *FROM user_basic WHERE name='DYG' range 如果使用索引获取某些范围间的记录，那么访问方法可能就是range，一般就是在WHERE语句中出现了between、\u003c、\u003e、!=、in等。这种范围扫描比全表扫描略好。 EXPLAIN SELECT *FROM user_basic WHERE name!='DYG' index 当使用覆盖索引，但是需要扫描全部索引时，对表的访问类型就是index EXPLAIN SELECT name,salt FROM user_basic WHERE salt != '111' all 全表扫描，为找到需要的数据，需要遍历全部的数据行 possible_keys与key possible_keys表示在对某个表进行单表查询时可能会用到的索引，key表示实际用到的索引，为NULL则表示没有使用索引 EXPLAIN SELECT phone,email FROM user_basic WHERE phone = '110' AND email = '2923780891@qq.com'; key_len key_len表示实际使用的索引所能记录的最大长度，比如上面使用的索引是phone char(15)，该表的编码是utf8mb4，那么该列的最大长度就是15*4=60字节，还有1字节用来记录值的实际长度。 rows 对某个表执行查询时，rows表示预计扫描的行数 EXPLAIN SELECT *FROM user_basic WHERE name!='DYG' filtered 查询优化器预测有多少条记录满⾜其余的搜索条件，什么意思呢？看具体的语句： EXPLAIN SELECT * FROM user_basic AS u INNER JOIN user_basic AS c ON u.id=c.id WHERE u.email \u003e 'choyeeku@gmail.com' and u.phone \u003e '12312' 从执行计划中可以看到，查询优化器将u看作驱动表，c看作被驱动表，u表扫描的行数预计是2787，filtered与等于50，说明过滤出2787*0.5=1394条数据，所以被驱动表只需要再进行大约1394次查询即可。 extra 额外信息：是否使用索引、是否使用where等等（关注度不高） ","date":"2024-05-31","objectID":"/mysql%E8%B0%83%E4%BC%98/:0:4","tags":["MySQL","数据库"],"title":"MySQL调优","uri":"/mysql%E8%B0%83%E4%BC%98/"},{"categories":["数据库"],"content":"查询优化器执行过程 1.如果是查询语句（select语句），首先会查询缓存是否已有相应结果，有则返回结果，无则进行下一步（如果不是查询语句，同样调到下一步） 2.解析查询，创建一个内部数据结构（解析树），这个解析树主要用来SQL语句的语义与语法解析； 3.优化：优化SQL语句，例如重写查询，决定表的读取顺序，以及选择需要的索引等。这一阶段用户是可以查询的，查询服务器优化器是如何进行优化的，便于用户重构查询和修改相关配置，达到最优化。这一阶段还涉及到存储引擎，优化器会询问存储引擎，比如某个操作的开销信息、是否对特定索引有查询优化等。 ","date":"2024-05-31","objectID":"/mysql%E8%B0%83%E4%BC%98/:0:5","tags":["MySQL","数据库"],"title":"MySQL调优","uri":"/mysql%E8%B0%83%E4%BC%98/"},{"categories":null,"content":"关于 LoveIt","date":"2019-08-02","objectID":"/about/","tags":null,"title":"关于 LoveIt","uri":"/about/"},{"categories":null,"content":"特性 ","date":"2019-08-02","objectID":"/about/:1:0","tags":null,"title":"关于 LoveIt","uri":"/about/"},{"categories":null,"content":"性能和 SEO  性能优化：在 Google PageSpeed Insights 中， 99/100 的移动设备得分和 100/100 的桌面设备得分  使用基于 JSON-LD 格式 的 SEO SCHEMA 文件进行 SEO 优化  支持 Google Analytics  支持 Fathom Analytics  支持 Plausible Analytics  支持 Yandex Metrica  支持搜索引擎的网站验证 (Google, Bind, Yandex and Baidu)  支持所有第三方库的 CDN  基于 lazysizes 自动转换图片为懒加载 ","date":"2019-08-02","objectID":"/about/:1:1","tags":null,"title":"关于 LoveIt","uri":"/about/"},{"categories":null,"content":"外观和布局  桌面端/移动端 响应式布局  浅色/深色 主题模式  全局一致的设计语言  支持分页  易用和自动展开的文章目录  支持多语言和国际化  美观的 CSS 动画 社交和评论系统  支持 Gravatar 头像  支持本地头像  支持多达 73 种社交链接  支持多达 24 种网站分享  支持 Disqus 评论系统  支持 Gitalk 评论系统  支持 Valine 评论系统  支持 Facebook comments 评论系统  支持 Telegram comments 评论系统  支持 Commento 评论系统  支持 utterances 评论系统  支持 giscus 评论系统 ","date":"2019-08-02","objectID":"/about/:1:2","tags":null,"title":"关于 LoveIt","uri":"/about/"},{"categories":null,"content":"扩展功能  支持基于 Lunr.js 或 algolia 的搜索  支持 Twemoji  支持代码高亮  一键复制代码到剪贴板  支持基于 lightGallery 的图片画廊  支持 Font Awesome 图标的扩展 Markdown 语法  支持上标注释的扩展 Markdown 语法  支持分数的扩展 Markdown 语法  支持基于 $\\KaTeX$ 的数学公式  支持基于 mermaid 的图表 shortcode  支持基于 ECharts 的交互式数据可视化 shortcode  支持基于 Mapbox GL JS 的 Mapbox shortcode  支持基于 APlayer 和 MetingJS 的音乐播放器 shortcode  支持 Bilibili 视频 shortcode  支持多种注释的 shortcode  支持自定义样式的 shortcode  支持自定义脚本的 shortcode  支持基于 TypeIt 的打字动画 shortcode  支持基于 cookieconsent 的 Cookie 许可横幅  支持人物标签的 shortcode … ","date":"2019-08-02","objectID":"/about/:1:3","tags":null,"title":"关于 LoveIt","uri":"/about/"},{"categories":null,"content":"许可协议 LoveIt 根据 MIT 许可协议授权。 更多信息请查看 LICENSE 文件。 ","date":"2019-08-02","objectID":"/about/:2:0","tags":null,"title":"关于 LoveIt","uri":"/about/"},{"categories":null,"content":"特别感谢 LoveIt 主题中用到了以下项目，感谢它们的作者： normalize.css Font Awesome Simple Icons Animate.css autocomplete Lunr.js algoliasearch lazysizes object-fit-images Twemoji emoji-data lightGallery clipboard.js Sharer.js TypeIt $\\KaTeX$ mermaid ECharts Mapbox GL JS APlayer MetingJS Gitalk Valine cookieconsent ","date":"2019-08-02","objectID":"/about/:3:0","tags":null,"title":"关于 LoveIt","uri":"/about/"}]